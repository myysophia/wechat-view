
<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>AI技术交流群 · 2025-10-25 群聊日报</title>
  <meta name="robots" content="noindex"/>
  <meta name="color-scheme" content="light dark"/>
  <link rel="prefetch" href="../index.html"/>
  <link rel="prefetch" href="../../index.html"/>
  <link rel="prefetch" href="/index.html"/>
  <style>
    :root {
      color-scheme: light dark;
      --bg: #f6f7fb;
      --fg: #161823;
      --muted: #5f6b7d;
      --card-bg: #ffffff;
      --border: #e0e4ef;
      --accent: #3563ff;
      --accent-soft: rgba(53, 99, 255, 0.15);
      --shadow: 0 8px 32px rgba(15, 23, 42, 0.08);
    }
    [data-theme="dark"] {
      --bg: #070a14;
      --fg: #e6ebff;
      --muted: #94a0c2;
      --card-bg: #0f1527;
      --border: #20263a;
      --accent: #7aa2ff;
      --accent-soft: rgba(122, 162, 255, 0.15);
      --shadow: 0 12px 40px rgba(7, 12, 26, 0.6);
    }
    * { box-sizing: border-box; }
    body {
      margin: 0;
      padding: 32px 24px 72px;
      font-family: "SF Pro Display", "Segoe UI", "PingFang SC", "Microsoft YaHei", system-ui, -apple-system, sans-serif;
      background: var(--bg);
      color: var(--fg);
      line-height: 1.7;
      max-width: 1080px;
      margin-left: auto;
      margin-right: auto;
    }
    a { color: var(--accent); text-decoration: none; }
    a:hover { text-decoration: underline; }
    .page-header {
      display: flex;
      justify-content: space-between;
      gap: 32px;
      flex-wrap: wrap;
      margin-bottom: 28px;
    }
    .page-header .title {
      flex: 1 1 280px;
    }
    .eyebrow {
      display: inline-flex;
      gap: 8px;
      align-items: center;
      padding: 4px 10px;
      border-radius: 999px;
      background: var(--accent-soft);
      color: var(--accent);
      font-size: 13px;
      letter-spacing: 0.04em;
    }
    h1 {
      margin: 12px 0 4px;
      font-size: 28px;
      font-weight: 700;
    }
    .subtitle {
      margin: 0;
      color: var(--muted);
      font-size: 15px;
    }
    .stat-chips {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(140px, 1fr));
      gap: 12px;
      min-width: 260px;
    }
    .chip {
      background: var(--card-bg);
      border: 1px solid var(--border);
      border-radius: 16px;
      padding: 16px 18px;
      box-shadow: var(--shadow);
    }
    .chip-label { display: block; font-size: 13px; color: var(--muted); }
    .chip-value { display: block; font-size: 26px; font-weight: 600; margin-top: 4px; }

    main { display: grid; gap: 24px; }

    .panel {
      background: var(--card-bg);
      border: 1px solid var(--border);
      border-radius: 20px;
      padding: 24px 28px;
      box-shadow: var(--shadow);
    }
    .panel-highlight {
      background: linear-gradient(135deg, rgba(53,99,255,0.08), rgba(53,99,255,0.02));
    }
    .panel h2 {
      margin: 0 0 14px;
      font-size: 20px;
    }
    .panel h3 { margin: 12px 0 6px; font-size: 16px; }
    .panel p.lead { font-size: 16px; margin-bottom: 12px; }

    .metric-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(220px, 1fr));
      gap: 16px;
    }
    .metric-card {
      padding: 18px;
      border-radius: 16px;
      border: 1px solid var(--border);
      background: rgba(255,255,255,0.55);
      backdrop-filter: blur(6px);
    }
    [data-theme="dark"] .metric-card {
      background: rgba(15, 21, 39, 0.65);
    }
    .metric-card strong { display: block; font-size: 14px; color: var(--muted); }
    .metric-card .value { font-size: 30px; font-weight: 700; margin: 6px 0; }
    .metric-card span { font-size: 13px; color: var(--muted); }

    .insight-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(240px, 1fr));
      gap: 20px;
    }
    .insight-grid ul {
      margin: 8px 0 0;
      padding-left: 20px;
    }
    .insight-grid li { margin-bottom: 6px; }

    .activity-bars {
      display: grid;
      grid-template-columns: repeat(24, minmax(10px, 1fr));
      gap: 6px;
      align-items: end;
      height: 160px;
      margin-top: 16px;
    }
    .activity-bar {
      position: relative;
      background: rgba(53, 99, 255, 0.08);
      border-radius: 8px 8px 2px 2px;
      overflow: hidden;
    }
    .activity-bar::after {
      content: "";
      position: absolute;
      inset: auto 0 0 0;
      height: calc(var(--value, 0) * 1%);
      min-height: 2px;
      background: linear-gradient(180deg, rgba(53,99,255,0.85), rgba(53,99,255,0.4));
    }
    .activity-labels {
      display: grid;
      grid-template-columns: repeat(24, minmax(10px, 1fr));
      gap: 6px;
      margin-top: 8px;
      font-size: 11px;
      color: var(--muted);
      text-align: center;
    }

    .list-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(260px, 1fr));
      gap: 20px;
      margin-top: 16px;
    }
    .rank-list { list-style: none; margin: 0; padding: 0; }
    .rank-item { margin-bottom: 14px; }
    .rank-item strong { font-size: 15px; }
    .rank-meter {
      height: 6px;
      background: var(--accent-soft);
      border-radius: 4px;
      margin-top: 6px;
      overflow: hidden;
    }
    .rank-meter span {
      display: block;
      height: 100%;
      background: var(--accent);
      width: var(--value, 0%);
    }

    .chip-list {
      display: flex;
      flex-wrap: wrap;
      gap: 10px;
      margin-top: 12px;
    }
    .chip-list span {
      padding: 6px 14px;
      border-radius: 999px;
      background: rgba(53, 99, 255, 0.12);
      color: var(--accent);
      font-size: 13px;
    }

    details.report-messages {
      margin-top: 12px;
    }
    details.report-messages summary {
      cursor: pointer;
      padding: 12px 16px;
      background: rgba(53, 99, 255, 0.08);
      border-radius: 12px;
      font-weight: 600;
    }
    .message-stream {
      margin-top: 16px;
      display: grid;
      gap: 16px;
    }
    .msg-card {
      border: 1px solid var(--border);
      border-radius: 16px;
      padding: 14px 16px;
      background: var(--card-bg);
    }
    .msg-meta {
      display: flex;
      justify-content: space-between;
      gap: 12px;
      font-size: 13px;
      color: var(--muted);
    }
    .msg-body { margin-top: 8px; font-size: 15px; white-space: pre-wrap; }
    .msg-body img { max-width: 100%; border-radius: 12px; }

    footer {
      margin-top: 32px;
      text-align: center;
      font-size: 12px;
      color: var(--muted);
    }
    @media (max-width: 720px) {
      body { padding: 18px 16px 56px; }
      .page-header { flex-direction: column; }
      .stat-chips { grid-template-columns: repeat(auto-fit, minmax(120px, 1fr)); }
      .activity-bars { height: 120px; }
    }
  </style>
  <script>
    document.documentElement.dataset.theme = matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
  </script>
</head>
<body>
  <header class="page-header">
    <div class="title">
      <span class="eyebrow">群聊日报</span>
      <h1>AI技术交流群</h1>
      <p class="subtitle">2025-10-25</p>
    </div>
    <div class="stat-chips">
      <div class="chip"><span class="chip-label">消息总数</span><span class="chip-value">65</span></div>
      <div class="chip"><span class="chip-label">活跃成员</span><span class="chip-value">12</span></div>
      <div class="chip"><span class="chip-label">图片消息</span><span class="chip-value">7</span></div>
    </div>
  </header>

  <main>
    <section class="panel">
      <h2>今日数据概览</h2>
      <div class="metric-grid">
        <div class="metric-card">
          <strong>峰值活跃时段</strong>
          <div class="value">00:00</div>
          <span>该时段共 44 条消息</span>
        </div>
        <div class="metric-card">
          <strong>Top 发送者</strong>
          
            <div class="value">IQ75</div>
            <span>发送 13 条</span>
          
        </div>
        <div class="metric-card">
          <strong>热门主题</strong>
          
            <div class="value">记忆</div>
            <span>共 14 次提及</span>
          
        </div>
        <div class="metric-card">
          <strong>热门链接数量</strong>
          <div class="value">1</div>
          
            <span>例如：mp.weixin.qq.com</span>
          
        </div>
        <div class="metric-card">
          <strong>群氛指数</strong>
          <div class="value">61</div>
          <span>讨论平稳</span>
        </div>
      </div>
      
      <h3>要点速览</h3>
      <ul>
        <li>消息 65 条，活跃 12 人；峰值 00:00-00:59</li><li>Top 发送者：IQ75(13)、详志(ip)(13)、WTY(9)</li><li>热门主题：记忆、agent、context</li><li>热门链接 1 个，例如 mp.weixin.qq.com</li><li>图片 7 张</li>
      </ul>
      
    </section>

    
    <section class="panel">
      <h2>群氛温度计</h2>
      <div class="metric-grid">
        <div class="metric-card">
          <strong>活跃度</strong>
          <div class="value">100%</div>
          <span>综合消息量与参与度</span>
        </div>
        <div class="metric-card">
          <strong>情绪指数</strong>
          <div class="value">45%</div>
          <span>正向表达占比</span>
        </div>
        <div class="metric-card">
          <strong>信息密度</strong>
          <div class="value">54%</div>
          <span>链接/长文/资料占比</span>
        </div>
        <div class="metric-card">
          <strong>争议度</strong>
          <div class="value">5%</div>
          <span>问答、@ 提及、感叹</span>
        </div>
      </div>
      
      <h3>氛围解读</h3>
      <ul>
        <li>活跃度高（65 条、12 人参与）</li><li>信息密度高（链接或长文较多）</li><li>讨论较温和，可适度引导观点碰撞</li>
      </ul>
      
    </section>
    

    
    <section class="panel panel-highlight">
      <h2>AI 洞察</h2>
      <p class="lead">2025年10月25日，AI技术交流群围绕LLM的记忆机制、Agent连续性与工程实践展开深度讨论，信息密度高，观点多元但氛围平稳。</p>
      <div class="insight-grid">
        
        <div>
          <h3>值得关注</h3>
          <ul><li>聚焦记忆管理：区分KV本能记忆、Context中短期记忆与RAG长期记忆</li><li>强调工程素养：提示词能力反映领域知识与计算机认知水平</li><li>探讨Agent连续性：需设计记忆迁移机制以实现经验积累</li><li>对比模型能力：通过多模型递进提问挖掘理解边界</li></ul>
        </div>
        
        
        <div>
          <h3>潜在机会</h3>
          <ul><li>整理记忆管理框架（如mem0、langmem）的选型指南</li><li>组织注意力机制与In-Context Learning原理小专题</li><li>推动spec-driven开发模式的最佳实践分享</li></ul>
        </div>
        
        
        <div>
          <h3>风险与预警</h3>
          <ul><li>讨论存在概念错位：理论认知与工程方案未充分对齐</li><li>部分成员对新手态度消极，可能抑制新人参与</li><li>关键问题如“最优Context压缩”尚无跟进解答</li></ul>
        </div>
        
        
        <div>
          <h3>建议行动</h3>
          <ul><li>汇总IQ75与WTY关于记忆分层的观点形成知识卡片</li><li>邀请详志(ip)分享DeepSeek消化后的理解</li><li>建立“未解问题”追踪清单，降低回复债务</li></ul>
        </div>
        
      </div>
      
      <p style="margin-top:18px;font-size:14px;color:var(--muted);">今日金句：“你每次新开一个agent session，得到的都是一个记忆清空的全新实例。”</p>
      
    </section>
    

    <section class="panel">
      <h2>互动热度</h2>
      <div class="activity-bars">
        
          <div class="activity-bar" style="--value: 100"></div>
        
          <div class="activity-bar" style="--value: 45.45454545454545"></div>
        
          <div class="activity-bar" style="--value: 0"></div>
        
          <div class="activity-bar" style="--value: 2.272727272727273"></div>
        
          <div class="activity-bar" style="--value: 0"></div>
        
          <div class="activity-bar" style="--value: 0"></div>
        
          <div class="activity-bar" style="--value: 0"></div>
        
          <div class="activity-bar" style="--value: 0"></div>
        
          <div class="activity-bar" style="--value: 0"></div>
        
          <div class="activity-bar" style="--value: 0"></div>
        
          <div class="activity-bar" style="--value: 0"></div>
        
          <div class="activity-bar" style="--value: 0"></div>
        
          <div class="activity-bar" style="--value: 0"></div>
        
          <div class="activity-bar" style="--value: 0"></div>
        
          <div class="activity-bar" style="--value: 0"></div>
        
          <div class="activity-bar" style="--value: 0"></div>
        
          <div class="activity-bar" style="--value: 0"></div>
        
          <div class="activity-bar" style="--value: 0"></div>
        
          <div class="activity-bar" style="--value: 0"></div>
        
          <div class="activity-bar" style="--value: 0"></div>
        
          <div class="activity-bar" style="--value: 0"></div>
        
          <div class="activity-bar" style="--value: 0"></div>
        
          <div class="activity-bar" style="--value: 0"></div>
        
          <div class="activity-bar" style="--value: 0"></div>
        
      </div>
      <div class="activity-labels">
        
          <span>00</span>
        
          <span>01</span>
        
          <span>02</span>
        
          <span>03</span>
        
          <span>04</span>
        
          <span>05</span>
        
          <span>06</span>
        
          <span>07</span>
        
          <span>08</span>
        
          <span>09</span>
        
          <span>10</span>
        
          <span>11</span>
        
          <span>12</span>
        
          <span>13</span>
        
          <span>14</span>
        
          <span>15</span>
        
          <span>16</span>
        
          <span>17</span>
        
          <span>18</span>
        
          <span>19</span>
        
          <span>20</span>
        
          <span>21</span>
        
          <span>22</span>
        
          <span>23</span>
        
      </div>
    </section>

    
    
    <section class="panel">
      <h2>回复债</h2>
      <div class="metric-grid">
        <div class="metric-card">
          <strong>待跟进问题</strong>
          <div class="value">1</div>
          <span>尚未收到回应</span>
        </div>
        <div class="metric-card">
          <strong>平均响应</strong>
          <div class="value">31.6</div>
          <span>分钟/问题</span>
        </div>
        <div class="metric-card">
          <strong>最佳催办时段</strong>
          
            <div class="value">00:00</div>
            <div class="chip-list" style="margin-top:8px;">
              <span>00:00</span><span>01:00</span>
            </div>
          
        </div>
      </div>
      <div class="list-grid">
        <div>
          <h3>待回复</h3>
          <ul class="rank-list">
            
              <li class="rank-item">
                <strong>WTY</strong> · 如何最优压缩，如何取最优信息送入context window，当然可以hard code去做这些，做做kv缓存优化啥的，就像manus走的那条路
                
                
                  <div style="margin-top:4px;font-size:12px;color:var(--muted);">已等待 142 分钟</div>
                
              </li>
            
          </ul>
        </div>
        <div>
          <h3>已解决</h3>
          <ul class="rank-list">
            
              <li class="rank-item">
                <strong>Quanzhi Fu-PhD在读</strong> · 腐烂是什么意思呢？
                
                  <div style="margin-top:4px;font-size:12px;color:var(--muted);">回复：IQ75</div>
                
                
                  <div style="margin-top:4px;font-size:12px;color:var(--muted);">用时 60.3 分钟</div>
                
              </li>
            
              <li class="rank-item">
                <strong>WTY</strong> · 如何处理记忆，是一个相当本质的元认知问题，可能需要专门的llm来处理，如果是确定性编程的，基本还是信息存取问题了，可能达不到认知控制的问题
                
                  <div style="margin-top:4px;font-size:12px;color:var(--muted);">回复：IQ75</div>
                
                
                  <div style="margin-top:4px;font-size:12px;color:var(--muted);">用时 2.9 分钟</div>
                
              </li>
            
          </ul>
        </div>
      </div>
    </section>
    

    <section class="panel">
      <h2>群内热议</h2>
      <div class="list-grid">
        <div>
          <h3>Top 发送者</h3>
          <ul class="rank-list">
            
              <li class="rank-item">
                <strong>IQ75</strong> · 13 条
                <div class="rank-meter"><span style="width: 20%;"></span></div>
              </li>
            
              <li class="rank-item">
                <strong>详志(ip)</strong> · 13 条
                <div class="rank-meter"><span style="width: 20%;"></span></div>
              </li>
            
              <li class="rank-item">
                <strong>WTY</strong> · 9 条
                <div class="rank-meter"><span style="width: 14%;"></span></div>
              </li>
            
              <li class="rank-item">
                <strong>鸭哥</strong> · 6 条
                <div class="rank-meter"><span style="width: 9%;"></span></div>
              </li>
            
              <li class="rank-item">
                <strong>CAI</strong> · 5 条
                <div class="rank-meter"><span style="width: 8%;"></span></div>
              </li>
            
          </ul>
        </div>
        <div>
          <h3>热门链接</h3>
          <ul class="rank-list">
            
              <li class="rank-item">
                <a href="https://mp.weixin.qq.com/s?__biz=MTMwNDMwODQ0MQ==&amp;mid=2653089187&amp;idx=1&amp;sn=f33e4c0054157402182804dc03b103d4&amp;chksm=7f1464b94700c3855d69cb6767f22dc27a5ea99f22a77acfa5858e6c94b36a36be4a7b171bcd&amp;mpshare=1&amp;scene=1&amp;srcid=1025sCn3VkNNYB0An5xgmxc4&amp;sharer_shareinfo=12edc90059c03651dd0ecd82daf37ee6&amp;sharer_shareinfo_first=12edc90059c03651dd0ecd82daf37ee6#rd" target="_blank" rel="noreferrer noopener" style="font-weight:600;display:inline-block;">
                  AI 正在接管代码，AWS 首席布道师却说：开发者的未来在「沟通」
                </a>
                
                  <div style="margin-top:4px;font-size:12px;color:var(--muted);">来源：mp.weixin.qq.com</div>
                
                
                  <div style="margin-top:6px;font-size:13px;color:var(--muted);">他曾定义了云计算的「叙事」，如今他选择回归 AI 时代的「构建」。</div>
                
                <div style="margin-top:6px;font-size:12px;word-break:break-all;">
                  <a href="https://mp.weixin.qq.com/s?__biz=MTMwNDMwODQ0MQ==&amp;mid=2653089187&amp;idx=1&amp;sn=f33e4c0054157402182804dc03b103d4&amp;chksm=7f1464b94700c3855d69cb6767f22dc27a5ea99f22a77acfa5858e6c94b36a36be4a7b171bcd&amp;mpshare=1&amp;scene=1&amp;srcid=1025sCn3VkNNYB0An5xgmxc4&amp;sharer_shareinfo=12edc90059c03651dd0ecd82daf37ee6&amp;sharer_shareinfo_first=12edc90059c03651dd0ecd82daf37ee6#rd" target="_blank" rel="noreferrer noopener">https://mp.weixin.qq.com/s?__biz=MTMwNDMwODQ0MQ==&amp;mid=2653089187&amp;idx=1&amp;sn=f33e4c0054157402182804dc03b103d4&amp;chksm=7f1464b94700c3855d69cb6767f22dc27a5ea99f22a77acfa5858e6c94b36a36be4a7b171bcd&amp;mpshare=1&amp;scene=1&amp;srcid=1025sCn3VkNNYB0An5xgmxc4&amp;sharer_shareinfo=12edc90059c03651dd0ecd82daf37ee6&amp;sharer_shareinfo_first=12edc90059c03651dd0ecd82daf37ee6#rd</a>
                </div>
              </li>
            
          </ul>
        </div>
        <div>
          <h3>主题概览</h3>
          <ul class="rank-list">
            
              <li class="rank-item">
                <strong>记忆</strong> · 14 次
                <div style="margin-top:6px;font-size:13px;color:var(--muted);">代表内容：现在人们对agent有一个很大的不切实际期望，就是你希望agent天然懂你，
特别是在你跟agent对话编程或者工作了很久之后，希望下次打开cursor, manus, cc； agent能记得上次我们协同工作时候的场景、经验、技能。

但如果不做记忆恢复，这是不可能的，你每次新开一个agent session，得到的都是一个记忆清空的全新的agent实例。

如果要想agent的工作更加有连续性，有积累，可自我迭代，就必须设计一套“记忆管理的工作机制”来实现记忆的记录、保存、迁移。</div>
              </li>
            
              <li class="rank-item">
                <strong>agent</strong> · 11 次
                <div style="margin-top:6px;font-size:13px;color:var(--muted);">代表内容：现在人们对agent有一个很大的不切实际期望，就是你希望agent天然懂你，
特别是在你跟agent对话编程或者工作了很久之后，希望下次打开cursor, manus, cc； agent能记得上次我们协同工作时候的场景、经验、技能。

但如果不做记忆恢复，这是不可能的，你每次新开一个agent session，得到的都是一个记忆清空的全新的agent实例。

如果要想agent的工作更加有连续性，有积累，可自我迭代，就必须设计一套“记忆管理的工作机制”来实现记忆的记录、保存、迁移。</div>
              </li>
            
              <li class="rank-item">
                <strong>context</strong> · 13 次
                <div style="margin-top:6px;font-size:13px;color:var(--muted);">代表内容：如果把LLM的kv也视为记忆的一种形式（小脑记忆），那么LLM的kv可以看做是一种内化的记忆，等同于人类的植物神经记忆（刻在DNA的本能）

对话窗口context是一种中短时记忆，你可以通过对context的变造、压缩、迭代扩充记忆的范围

可以用于agent使用，保留在文档、临时文件的内容，可以视为长期记忆（量大，读取慢）</div>
              </li>
            
              <li class="rank-item">
                <strong>问题</strong> · 9 次
                <div style="margin-top:6px;font-size:13px;color:var(--muted);">代表内容：开三个窗口，GPT5 pro, Claude opus, Gemini pro在一个问题上问30个递进的问题，就有些理解了，但一定要多动脑子，针对他回答的漏洞攻击 
他论文说这个问题，工作记忆和长期记忆的架构，和 incontext learning llm rag的关系很像，但实际上现在认知机理层面还很不清楚</div>
              </li>
            
              <li class="rank-item">
                <strong>llm</strong> · 5 次
                <div style="margin-top:6px;font-size:13px;color:var(--muted);">代表内容：开三个窗口，GPT5 pro, Claude opus, Gemini pro在一个问题上问30个递进的问题，就有些理解了，但一定要多动脑子，针对他回答的漏洞攻击 
他论文说这个问题，工作记忆和长期记忆的架构，和 incontext learning llm rag的关系很像，但实际上现在认知机理层面还很不清楚</div>
              </li>
            
          </ul>
        </div>
      </div>
      
      <h3>关键词热度</h3>
      <div class="chip-list">
        <span>记忆 · 31</span><span>agent · 25</span><span>context · 14</span><span>问题 · 14</span><span>llm · 12</span><span>一种 · 8</span><span>信息 · 7</span><span>是一 · 7</span><span>注意 · 7</span><span>的记 · 7</span><span>管理 · 7</span><span>讨论 · 7</span><span>忆的 · 6</span><span>意力 · 6</span><span>机制 · 6</span><span>注意力 · 6</span><span>的记忆 · 6</span><span>记忆的 · 6</span><span>东西 · 5</span><span>了一 · 5</span>
      </div>
      
    </section>

    <section class="panel">
      <h2>消息时间线</h2>
      <details class="report-messages">
        <summary>展开查看 65 条历史消息</summary>
        <div class="message-stream">
          
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:00:16&#43;08:00</span>
                <span>linhow</span>
              </div>
              <div class="msg-body">
                
              有一次我用这个车轱辘话，居然起作用了：
        你已经连续三次修改失败了，你不应该在这个根因上钻牛角尖试探，而应该系统审视架构合理性来寻找解决问题方案
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:00:21&#43;08:00</span>
                <span>马工</span>
              </div>
              <div class="msg-body">
                
              这些都是菜鸟。菜鸟缺乏基本的工程素养和沟通能力，只会嘲笑ai
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:00:42&#43;08:00</span>
                <span>详志(ip)</span>
              </div>
              <div class="msg-body">
                
              这有关键信息呀，解决方向
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:03:39&#43;08:00</span>
                <span>薇冷 Violet</span>
              </div>
              <div class="msg-body">
                
              写好编程提示词背后是基本的工程素养和计算机认知能力
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:04:14&#43;08:00</span>
                <span>WTY</span>
              </div>
              <div class="msg-body">
                
              开三个窗口，GPT5 pro, Claude opus, Gemini pro在一个问题上问30个递进的问题，就有些理解了，但一定要多动脑子，针对他回答的漏洞攻击 
他论文说这个问题，工作记忆和长期记忆的架构，和 incontext learning llm rag的关系很像，但实际上现在认知机理层面还很不清楚
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:04:53&#43;08:00</span>
                <span>详志(ip)</span>
              </div>
              <div class="msg-body">
                
              嗯，后面我追问，给的解决方案就是 rag 之类的
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:05:21&#43;08:00</span>
                <span>详志(ip)</span>
              </div>
              <div class="msg-body">
                
                  
                  
                    <a href="http://10.40.61.135:5030/image/37badbffc5c9de6e876e6f426a136a7f,msg%5cattach%5cd372d56eda240a7412ec82e4e74b6ed4%5c2025-10%5cImg%5c5363b881ee66a605c7ce4b7cb48ac985" target="_blank" rel="noreferrer noopener"><img src="http://10.40.61.135:5030/image/37badbffc5c9de6e876e6f426a136a7f,msg%5cattach%5cd372d56eda240a7412ec82e4e74b6ed4%5c2025-10%5cImg%5c5363b881ee66a605c7ce4b7cb48ac985" data-media-src="http://10.40.61.135:5030/image/37badbffc5c9de6e876e6f426a136a7f,msg%5cattach%5cd372d56eda240a7412ec82e4e74b6ed4%5c2025-10%5cImg%5c5363b881ee66a605c7ce4b7cb48ac985" alt="图片"/></a>
                  
                
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:07:16&#43;08:00</span>
                <span>WTY</span>
              </div>
              <div class="msg-body">
                
              提示词其实是自己领域知识的萃取，只是in context  learning由于原理限制不要期望智力太好，太长也腐烂严重
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:08:30&#43;08:00</span>
                <span>Quanzhi Fu-PhD在读</span>
              </div>
              <div class="msg-body">
                
              腐烂是什么意思呢？
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:09:42&#43;08:00</span>
                <span>WTY</span>
              </div>
              <div class="msg-body">
                
              这些方法避开了元认知控制的关键问题，想ad hoc的化简为信息存取，可以基于目前现成东西有些提升，但不可能质变
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:09:44&#43;08:00</span>
                <span>详志(ip)</span>
              </div>
              <div class="msg-body">
                
                  
                  
                    <a href="http://10.40.61.135:5030/image/3b04a9e5e794fa42b381034b2320eb08,msg%5cattach%5cd372d56eda240a7412ec82e4e74b6ed4%5c2025-10%5cImg%5c0cf527f5b16feff3b9fb83b175d7f376" target="_blank" rel="noreferrer noopener"><img src="http://10.40.61.135:5030/image/3b04a9e5e794fa42b381034b2320eb08,msg%5cattach%5cd372d56eda240a7412ec82e4e74b6ed4%5c2025-10%5cImg%5c0cf527f5b16feff3b9fb83b175d7f376" data-media-src="http://10.40.61.135:5030/image/3b04a9e5e794fa42b381034b2320eb08,msg%5cattach%5cd372d56eda240a7412ec82e4e74b6ed4%5c2025-10%5cImg%5c0cf527f5b16feff3b9fb83b175d7f376" alt="图片"/></a>
                  
                
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:10:37&#43;08:00</span>
                <span>详志(ip)</span>
              </div>
              <div class="msg-body">
                
              嗯，这个是基于我的不专业问题“在当下的技术框架下，有办法把置信度低的权重扔掉吗，如果扔掉有没可能会产生什么反作用”做的回答
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:11:34&#43;08:00</span>
                <span>WTY</span>
              </div>
              <div class="msg-body">
                
              注意力机制的原理还是很重要的，最好学到这种程度，一种架构策略出来了，能分析对注意力机制起什么作用
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:13:42&#43;08:00</span>
                <span>WTY</span>
              </div>
              <div class="msg-body">
                
              比如，为何正向和反向提示词的效果是不对称的
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:14:48&#43;08:00</span>
                <span>详志(ip)</span>
              </div>
              <div class="msg-body">
                
              上一次听群友说注意力机制对不同位置信息的权重时就想到了，还是要打打基础
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:16:47&#43;08:00</span>
                <span>WTY</span>
              </div>
              <div class="msg-body">
                
              还包括多头注意力的激活，高势差语义对提示词的影响等
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:19:05&#43;08:00</span>
                <span>鸭哥</span>
              </div>
              <div class="msg-body">
                
              👍🏿👍🏿
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:19:14&#43;08:00</span>
                <span>鸭哥</span>
              </div>
              <div class="msg-body">
                
              👍🏿👍🏿
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:22:30&#43;08:00</span>
                <span>详志(ip)</span>
              </div>
              <div class="msg-body">
                
              我找 deepseek 消化一下...
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:28:16&#43;08:00</span>
                <span>马工</span>
              </div>
              <div class="msg-body">
                
                  
                  
                    <a href="http://10.40.61.135:5030/image/a3085bb842307180b77ffbcd4e93086e,msg%5cattach%5cd372d56eda240a7412ec82e4e74b6ed4%5c2025-10%5cImg%5c714686d4d9e124b446c39c23f247070e" target="_blank" rel="noreferrer noopener"><img src="http://10.40.61.135:5030/image/a3085bb842307180b77ffbcd4e93086e,msg%5cattach%5cd372d56eda240a7412ec82e4e74b6ed4%5c2025-10%5cImg%5c714686d4d9e124b446c39c23f247070e" data-media-src="http://10.40.61.135:5030/image/a3085bb842307180b77ffbcd4e93086e,msg%5cattach%5cd372d56eda240a7412ec82e4e74b6ed4%5c2025-10%5cImg%5c714686d4d9e124b446c39c23f247070e" alt="图片"/></a>
                  
                
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:28:30&#43;08:00</span>
                <span>马工</span>
              </div>
              <div class="msg-body">
                
                  
                  
                    <a href="http://10.40.61.135:5030/image/975e21bc7100032a71ae4fb6ffc13af0,msg%5cattach%5cd372d56eda240a7412ec82e4e74b6ed4%5c2025-10%5cImg%5c8812397da4ced7597f7b4625a9599e25" target="_blank" rel="noreferrer noopener"><img src="http://10.40.61.135:5030/image/975e21bc7100032a71ae4fb6ffc13af0,msg%5cattach%5cd372d56eda240a7412ec82e4e74b6ed4%5c2025-10%5cImg%5c8812397da4ced7597f7b4625a9599e25" data-media-src="http://10.40.61.135:5030/image/975e21bc7100032a71ae4fb6ffc13af0,msg%5cattach%5cd372d56eda240a7412ec82e4e74b6ed4%5c2025-10%5cImg%5c8812397da4ced7597f7b4625a9599e25" alt="图片"/></a>
                  
                
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:28:42&#43;08:00</span>
                <span>详志(ip)</span>
              </div>
              <div class="msg-body">
                
              [666]
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:29:13&#43;08:00</span>
                <span>CAI</span>
              </div>
              <div class="msg-body">
                
              哈哈
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:29:14&#43;08:00</span>
                <span>CAI</span>
              </div>
              <div class="msg-body">
                
                  
                  
                    <a href="http://10.40.61.135:5030/image/d14d8c6cb803f9a524500cc66d851e8a,msg%5cattach%5cd372d56eda240a7412ec82e4e74b6ed4%5c2025-10%5cImg%5cee9dad577a8b7efb088a840b6c3e43c0" target="_blank" rel="noreferrer noopener"><img src="http://10.40.61.135:5030/image/d14d8c6cb803f9a524500cc66d851e8a,msg%5cattach%5cd372d56eda240a7412ec82e4e74b6ed4%5c2025-10%5cImg%5cee9dad577a8b7efb088a840b6c3e43c0" data-media-src="http://10.40.61.135:5030/image/d14d8c6cb803f9a524500cc66d851e8a,msg%5cattach%5cd372d56eda240a7412ec82e4e74b6ed4%5c2025-10%5cImg%5cee9dad577a8b7efb088a840b6c3e43c0" alt="图片"/></a>
                  
                
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:29:27&#43;08:00</span>
                <span>系统消息</span>
              </div>
              <div class="msg-body">
                
              &#34;CAI&#34; 撤回了一条消息
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:29:35&#43;08:00</span>
                <span>CAI</span>
              </div>
              <div class="msg-body">
                
              这个残酷真相补充的还挺灵性
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:29:37&#43;08:00</span>
                <span>详志(ip)</span>
              </div>
              <div class="msg-body">
                
              残酷真相...
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:31:28&#43;08:00</span>
                <span>鸭哥</span>
              </div>
              <div class="msg-body">
                
              [憨笑]
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:41:04&#43;08:00</span>
                <span>IQ75</span>
              </div>
              <div class="msg-body">
                
              有相关的论文的，我记得之前发过
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:41:33&#43;08:00</span>
                <span>详志(ip)</span>
              </div>
              <div class="msg-body">
                
              嗯嗯，上次看你们讨论
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:42:14&#43;08:00</span>
                <span>WTY</span>
              </div>
              <div class="msg-body">
                
              基于刚才群里在讨论的问题，我建议可以用这个问题作为药引子去理解注意力机制：in context learning多大程度上是鹦鹉学舌，和预训练比智力差多少
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:43:23&#43;08:00</span>
                <span>Quanzhi Fu-PhD在读</span>
              </div>
              <div class="msg-body">
                
              [ThumbsUp][ThumbsUp]专业啊专业，所以这个问题有答案吗，还是说目前还是open problem
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:44:07&#43;08:00</span>
                <span>Quanzhi Fu-PhD在读</span>
              </div>
              <div class="msg-body">
                
              in conetxt learning的能力决定了做agent时context engineering的上线
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:44:44&#43;08:00</span>
                <span>IQ75</span>
              </div>
              <div class="msg-body">
                
              context engineering，其实是在处理llm的记忆问题。
对llm来说，记忆内容是可以变造、压缩、隔离、迁移的。
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:46:17&#43;08:00</span>
                <span>IQ75</span>
              </div>
              <div class="msg-body">
                
              我已经在QCon上看到很多嘉宾在分享Agent infra和memory管理的主题了

开源社区里貌似有不少针对context engineering的记忆管理框架， langmem, mem0, memos这样的，都是针对agent的context管理、推理加速（应用层）而提出的解决方案。 

建议可以关注一下。
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:48:27&#43;08:00</span>
                <span>WTY</span>
              </div>
              <div class="msg-body">
                
              如何处理记忆，是一个相当本质的元认知问题，可能需要专门的llm来处理，如果是确定性编程的，基本还是信息存取问题了，可能达不到认知控制的问题
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:48:39&#43;08:00</span>
                <span>IQ75</span>
              </div>
              <div class="msg-body">
                
              昨天会场上跟一个老哥讨论agent跟现实中的人最大的差别在哪里。

最大的差异就是，你社招一个人加入公司，其实你购买的是这个人的“过往经验&#43;技能”，这里的人可以视为一种记忆的载体。

而agent本身是缺少这种记忆沉淀的，对LLM的底层调用本身是无状态的幂等调用，你要想让agent表现得更加有人味儿，得把agent曾经的记忆迁移到新的agent session里。
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:51:21&#43;08:00</span>
                <span>IQ75</span>
              </div>
              <div class="msg-body">
                
              有点故弄玄虚了，没有那么高深的东西，你用langchain agent做开发，编排多轮对话的上下文管理就知道，这里的“记忆”，你可以认为就是chat history (system/user/assistant)的内容，只不过要有效管理起来（隔离、压缩、迭代），这时候context就是一种中短期记忆
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:53:51&#43;08:00</span>
                <span>IQ75</span>
              </div>
              <div class="msg-body">
                
              如果把LLM的kv也视为记忆的一种形式（小脑记忆），那么LLM的kv可以看做是一种内化的记忆，等同于人类的植物神经记忆（刻在DNA的本能）

对话窗口context是一种中短时记忆，你可以通过对context的变造、压缩、迭代扩充记忆的范围

可以用于agent使用，保留在文档、临时文件的内容，可以视为长期记忆（量大，读取慢）
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:55:27&#43;08:00</span>
                <span>IQ75</span>
              </div>
              <div class="msg-body">
                
              如果我们希望agent的表现能更像人，那么要做的事情就是把我们对话训练了一段时间的agent记忆，可以独立保存下来，并可以移植到新的agent 上，这样就能取得连贯的agent使用体验
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:57:10&#43;08:00</span>
                <span>CAI</span>
              </div>
              <div class="msg-body">
                
              重要要长期记忆的文档保存，agent新建了，或者遗忘了重新读取下，很多时候够用了
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:57:53&#43;08:00</span>
                <span>IQ75</span>
              </div>
              <div class="msg-body">
                
              是呀，所以claude skill这个概念很好，可以视为一种“明文记忆”的打包
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:58:21&#43;08:00</span>
                <span>WTY</span>
              </div>
              <div class="msg-body">
                
              如何最优压缩，如何取最优信息送入context window，当然可以hard code去做这些，做做kv缓存优化啥的，就像manus走的那条路
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T00:59:40&#43;08:00</span>
                <span>IQ75</span>
              </div>
              <div class="msg-body">
                
              实际上我自己在用BMAD做AI coding，在几个不同的项目之间切换还能恢复到当时的开发场景，就是靠analyst读取prd/story的进度，比对代码实现状态，激活agent回到当时的开发节点。 

这个操作暗合了“恢复记忆”的思路
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T01:02:15&#43;08:00</span>
                <span>详志(ip)</span>
              </div>
              <div class="msg-body">
                
              感觉你们讨论的不是同一个东西，WTY 可能还在说我前面说的“知识的诅咒”引发的讨论，IQ75 是在说基于当下模型能力做的工程化解决方法...
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T01:02:51&#43;08:00</span>
                <span>详志(ip)</span>
              </div>
              <div class="msg-body">
                
              spec-driven 基本都是这套路了，通过文件来跨会话通信
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T01:03:00&#43;08:00</span>
                <span>CAI</span>
              </div>
              <div class="msg-body">
                
              本来也没讨论一个东西啊，fork了
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T01:03:14&#43;08:00</span>
                <span>详志(ip)</span>
              </div>
              <div class="msg-body">
                
              [旺柴]
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T01:03:25&#43;08:00</span>
                <span>IQ75</span>
              </div>
              <div class="msg-body">
                
              现在人们对agent有一个很大的不切实际期望，就是你希望agent天然懂你，
特别是在你跟agent对话编程或者工作了很久之后，希望下次打开cursor, manus, cc； agent能记得上次我们协同工作时候的场景、经验、技能。

但如果不做记忆恢复，这是不可能的，你每次新开一个agent session，得到的都是一个记忆清空的全新的agent实例。

如果要想agent的工作更加有连续性，有积累，可自我迭代，就必须设计一套“记忆管理的工作机制”来实现记忆的记录、保存、迁移。
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T01:04:38&#43;08:00</span>
                <span>Quanzhi Fu-PhD在读</span>
              </div>
              <div class="msg-body">
                
              哈哈哈确实，我们之前讨论的是context和llm中的权重有什么本质区别
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T01:05:22&#43;08:00</span>
                <span>IQ75</span>
              </div>
              <div class="msg-body">
                
              spec-driven是一种记忆迁移的方式，这个我认可的，只不过LLM的注意力机制问题，导致作为“外存”的文档，再次加载到llm context window之后，会存在信息衰减，你希望agent恢复的记忆可能不会达到你想要的程度。 

memory需要更精细地管理
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T01:07:47&#43;08:00</span>
                <span>系统消息</span>
              </div>
              <div class="msg-body">
                
              &#34;IQ75&#34; 撤回了一条消息
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T01:08:46&#43;08:00</span>
                <span>陈明</span>
              </div>
              <div class="msg-body">
                
              
              
                <div style="margin-top:8px;padding:12px;border:1px solid var(--border);border-radius:12px;background:rgba(53,99,255,0.05);">
                  <strong>AI 正在接管代码，AWS 首席布道师却说：开发者的未来在「沟通」</strong>
                  <div style="margin-top:4px;font-size:13px;color:var(--muted);">他曾定义了云计算的「叙事」，如今他选择回归 AI 时代的「构建」。</div>
                  <div style="margin-top:8px;font-size:13px;"><a href="https://mp.weixin.qq.com/s?__biz=MTMwNDMwODQ0MQ==&amp;mid=2653089187&amp;idx=1&amp;sn=f33e4c0054157402182804dc03b103d4&amp;chksm=7f1464b94700c3855d69cb6767f22dc27a5ea99f22a77acfa5858e6c94b36a36be4a7b171bcd&amp;mpshare=1&amp;scene=1&amp;srcid=1025sCn3VkNNYB0An5xgmxc4&amp;sharer_shareinfo=12edc90059c03651dd0ecd82daf37ee6&amp;sharer_shareinfo_first=12edc90059c03651dd0ecd82daf37ee6#rd" target="_blank" rel="noreferrer noopener">https://mp.weixin.qq.com/s?__biz=MTMwNDMwODQ0MQ==&amp;mid=2653089187&amp;idx=1&amp;sn=f33e4c0054157402182804dc03b103d4&amp;chksm=7f1464b94700c3855d69cb6767f22dc27a5ea99f22a77acfa5858e6c94b36a36be4a7b171bcd&amp;mpshare=1&amp;scene=1&amp;srcid=1025sCn3VkNNYB0An5xgmxc4&amp;sharer_shareinfo=12edc90059c03651dd0ecd82daf37ee6&amp;sharer_shareinfo_first=12edc90059c03651dd0ecd82daf37ee6#rd</a></div>
                </div>
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T01:08:48&#43;08:00</span>
                <span>IQ75</span>
              </div>
              <div class="msg-body">
                
              我前面提到过我的理解：

- LLM kv：本能的植物神经记忆。就像人天然会呼吸、心跳，而不会去注意到这些行为，这是你在应用层变造不了的东西。
- context: 通过对话、工具调用、environment交互后形成的中短期记忆
- RAG：长期的可持久化的记忆。
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T01:09:35&#43;08:00</span>
                <span>陈明</span>
              </div>
              <div class="msg-body">
                
              开发者正在从 developer 变为 builder
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T01:09:42&#43;08:00</span>
                <span>Quanzhi Fu-PhD在读</span>
              </div>
              <div class="msg-body">
                
              我印象里manus的blog里提到过，最近的prompt权重最高。所以他们每次都会把todo.md 附加在prompt的最底部，可以提高agent follow计划的能力
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T01:09:48&#43;08:00</span>
                <span>陈明</span>
              </div>
              <div class="msg-body">
                
              和之前不是一个概念了
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T01:10:48&#43;08:00</span>
                <span>系统消息</span>
              </div>
              <div class="msg-body">
                
              &#34;IQ75&#34; 撤回了一条消息
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T01:11:04&#43;08:00</span>
                <span>IQ75</span>
              </div>
              <div class="msg-body">
                
              你提供的context里重要信息的 位置、长度、关键字，都会影响LLM的理解和权重分配。
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T01:16:05&#43;08:00</span>
                <span>马工</span>
              </div>
              <div class="msg-body">
                
              🌿，俄国和北约直接开火了
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T01:19:38&#43;08:00</span>
                <span>鸭哥</span>
              </div>
              <div class="msg-body">
                
                  
                  
                    <a href="http://10.40.61.135:5030/image/7e77d02c44d3e825d3bd0733524fee72,msg%5cattach%5cd372d56eda240a7412ec82e4e74b6ed4%5c2025-10%5cImg%5c5cbe09e0c66adc858f3a205402ef56d5" target="_blank" rel="noreferrer noopener"><img src="http://10.40.61.135:5030/image/7e77d02c44d3e825d3bd0733524fee72,msg%5cattach%5cd372d56eda240a7412ec82e4e74b6ed4%5c2025-10%5cImg%5c5cbe09e0c66adc858f3a205402ef56d5" data-media-src="http://10.40.61.135:5030/image/7e77d02c44d3e825d3bd0733524fee72,msg%5cattach%5cd372d56eda240a7412ec82e4e74b6ed4%5c2025-10%5cImg%5c5cbe09e0c66adc858f3a205402ef56d5" alt="图片"/></a>
                  
                
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T01:19:41&#43;08:00</span>
                <span>鸭哥</span>
              </div>
              <div class="msg-body">
                
              卧槽，真的，学习了一下
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T01:21:11&#43;08:00</span>
                <span>tony</span>
              </div>
              <div class="msg-body">
                
              这个secondmind是啥
              
            
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T01:55:55&#43;08:00</span>
                <span>马工</span>
              </div>
              <div class="msg-body">
                
                  
                  
                    <a href="http://10.40.61.135:5030/image/19c30cfd1bfb0b64b15790166a5e38b1,msg%5cattach%5cd372d56eda240a7412ec82e4e74b6ed4%5c2025-10%5cImg%5c08553dec5bb61708b560c55f275e27bf" target="_blank" rel="noreferrer noopener"><img src="http://10.40.61.135:5030/image/19c30cfd1bfb0b64b15790166a5e38b1,msg%5cattach%5cd372d56eda240a7412ec82e4e74b6ed4%5c2025-10%5cImg%5c08553dec5bb61708b560c55f275e27bf" data-media-src="http://10.40.61.135:5030/image/19c30cfd1bfb0b64b15790166a5e38b1,msg%5cattach%5cd372d56eda240a7412ec82e4e74b6ed4%5c2025-10%5cImg%5c08553dec5bb61708b560c55f275e27bf" alt="图片"/></a>
                  
                
          </div>
        </div>
        
            <div class="msg-card">
              <div class="msg-meta">
                <span>2025-10-25T03:20:28&#43;08:00</span>
                <span>鸭哥</span>
              </div>
              <div class="msg-body">
                
              是我自己搓的一个AI
              
            
          </div>
        </div>
        
      </div>
      </details>
    </section>
  </main>

  <footer>由 wechat-view 自动生成 · 2025-10-25</footer>
  <script>
    document.addEventListener('error', function (event) {
      var target = event.target;
      if (target && target.dataset && target.dataset.mediaSrc && target.tagName === 'IMG') {
        var wrapper = document.createElement('div');
        wrapper.style.marginTop = '8px';
        var video = document.createElement('video');
        video.src = target.dataset.mediaSrc;
        video.controls = true;
        video.playsInline = true;
        video.style.maxWidth = '100%';
        video.style.borderRadius = '12px';
        wrapper.appendChild(video);
        target.replaceWith(wrapper);
      }
    }, true);
  </script>
</body>
</html>
