{
  "aiInsights": {
    "overview": "2025年10月24日群内围绕LLM、token压缩与DeepSeek OCR展开技术讨论，同时穿插对行业现状与AI落地效率的反思。",
    "highlights": [
      "DeepSeek OCR引发热议，焦点在视觉token压缩效率与信息论边界",
      "多位成员强调“先做出来再说”，推崇快速验证而非冗长讨论",
      "指出当前AI媒体存在标题党、硬蹭流量问题",
      "讨论DBA角色衰退与技术人才迭代机制"
    ],
    "opportunities": [
      "探索视觉模态在LLM上下文压缩中的实际应用",
      "推动轻量级协作开发模式，缩短项目启动周期",
      "建立更有效的技术社区问答响应机制"
    ],
    "risks": [
      "对AI能力过度乐观可能导致项目预期失控",
      "关键问题（如智谱销售对接）未获回应，存在协作断点",
      "技术讨论偶陷术语之争，影响信息传递效率"
    ],
    "actions": [
      "跟进DeepSeek OCR实测效果，组织小范围验证",
      "梳理未回复问题清单，定向邀请相关专家回应",
      "引导群内讨论聚焦可执行议题，减少空泛争论"
    ],
    "spotlight": "“写给懂的人看没流量，写给不懂的人看，不拉上AI没流量。”"
  },
  "date": "2025-10-24",
  "keyword": "",
  "summary": {
    "totalMessages": 92,
    "uniqueSenders": 20,
    "topSenders": [
      {
        "key": "wxid_xsrpijjy5ljx22",
        "count": 17
      },
      {
        "key": "CuBiCWu",
        "count": 11
      },
      {
        "key": "netcmcc",
        "count": 10
      },
      {
        "key": "a25880165",
        "count": 8
      },
      {
        "key": "michael24",
        "count": 8
      }
    ],
    "topLinks": [
      "https://mp.weixin.qq.com/s?__biz=MzA5NzU3MDczNA==\u0026mid=2247489289\u0026idx=1\u0026sn=919a537ad25e536bfd179d5a4144031d\u0026chksm=9112f86f41a9dcd544741cfb29af58811fd336c7b3ea8a414262a8969abc32539b03f6295acc\u0026mpshare=1\u0026scene=1\u0026srcid=1024ymuWFTz0uRvQZaJKBdlY\u0026sharer_shareinfo=9771bf115a53face98d1169915014b2c\u0026sharer_shareinfo_first=9771bf115a53face98d1169915014b2c#rd",
      "https://mp.weixin.qq.com/s?__biz=MzIzOTU0NTQ0MA==\u0026mid=2247554461\u0026idx=1\u0026sn=e52d01dd0832ede6a6cc146c152b39a1\u0026chksm=e8b35b5af8820fa373291ccb76d41f7176c52bedf3c0ff596187ede95bf92a5ba73ef2064e17\u0026mpshare=1\u0026scene=1\u0026srcid=1024jZdvIUwqixmWrGStZR8E\u0026sharer_shareinfo=8e7eebafc39ba27d77990e4c87f0edac\u0026sharer_shareinfo_first=8e7eebafc39ba27d77990e4c87f0edac#rd",
      "https://mp.weixin.qq.com/s?__biz=MzkzNjUwODAwNw==\u0026mid=2247487618\u0026idx=1\u0026sn=6111129aa497de81cdd1dc960b2ade4c\u0026chksm=c3994a438d7ba19afb2bcd991dd20822d0f9b5d61939de2e7b06e10ce1c8f243e8399ff46d6f\u0026mpshare=1\u0026scene=1\u0026srcid=1024ma0PS80GTKM6HRkQRS1L\u0026sharer_shareinfo=324f7bb7ee07a2563d381d4f0ae5e29e\u0026sharer_shareinfo_first=720a0770c136fff727517f8d4882b53e#rd"
    ],
    "hourlyHistogram": [
      11,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      1,
      0,
      0,
      31,
      44,
      5,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "keywords": [
      {
        "key": "llm",
        "count": 28
      },
      {
        "key": "token",
        "count": 24
      },
      {
        "key": "信息",
        "count": 17
      },
      {
        "key": "文本",
        "count": 15
      },
      {
        "key": "幻觉",
        "count": 14
      },
      {
        "key": "非常",
        "count": 14
      },
      {
        "key": "压缩",
        "count": 13
      },
      {
        "key": "文字",
        "count": 13
      },
      {
        "key": "ocr",
        "count": 11
      },
      {
        "key": "出来",
        "count": 11
      },
      {
        "key": "的文",
        "count": 11
      },
      {
        "key": "了一",
        "count": 10
      },
      {
        "key": "图片",
        "count": 10
      },
      {
        "key": "问题",
        "count": 10
      },
      {
        "key": "tokenizer",
        "count": 9
      },
      {
        "key": "图像",
        "count": 9
      },
      {
        "key": "记忆",
        "count": 9
      },
      {
        "key": "deepseek",
        "count": 8
      },
      {
        "key": "但是",
        "count": 8
      },
      {
        "key": "内容",
        "count": 8
      }
    ],
    "peakHour": 12,
    "highlights": [
      "消息 92 条，活跃 20 人；峰值 12:00-12:59",
      "Top 发送者：wxid_xsrpijjy5ljx22(17)、CuBiCWu(11)、netcmcc(10)",
      "热门主题：llm、token、信息",
      "热门链接 3 个，例如 mp.weixin.qq.com",
      "图片 12 张"
    ],
    "topics": [
      {
        "name": "llm",
        "keywords": [
          "llm"
        ],
        "count": 4,
        "representative": "是的。文字是符号，只需要用高效编码表达符号就可以了。llm会有更多的东西，比如 语义，embeding就是把文字转为语义吧。语义的维度越高，产生的token越大。"
      },
      {
        "name": "token",
        "keywords": [
          "token"
        ],
        "count": 11,
        "representative": "分享一些针对Deepseek OCR的学习笔记。注意这些材料在直观性和严谨性上更强调直观性。如果希望有严谨性的话还是得去看原论文。\n\nDeepSeekOCR想解决的问题其实跟 OCR 没关系。它的直接出发点非常 DeepSeek。就是 LLM 是基于 Transformer 的，Transformer context window 一长，它不论是占用的显存还是需要的算力都是平方量级增长的，又慢又贵。Deepseek用了一个非常直观的方法去部分解决这个问题：token 压缩。比如 100 个 token 的文本，我用其他模态比如图片，可能 10 个 token 就能表达出来同样的含义，这样就可以省很多钱，也可以用更小的显卡。\n\n但是如果真的要做这件事情，一个正统的方法是，我们把普通 LLM 前面的 tokenizer 从文本 tokenizer 换成图像的 tokenizer，然后从头训练一个 LLM，然后在各种任务上面测试，比如让它写程序、做问答、调用工具，看看效果会不会变好。很显然这个非常重量级。那有没有一个任务，它又能验证这种信息压缩的思路对不对，又能不要这么重量级，又足够有说服力呢？OCR 就是一个这样的例子。\n\n具体地说，DeepSeek 先是把文本渲染成图像，这样就知道原始信息ground truth是什么。然后再把图像用他们的 tokenizer 进行处理，得到一堆token，这一步跟文本得到token概念上类似。然后再用一个非常小的 3B 的 LLM 进行解码。就是问它：你从这些 token 里面能不能反推出来它最初输入的那些文本是什么。这就形成了一个定量的 evaluation 的框架。基于这个框架，他们给出了一个非常惊人的结果，原来有 1000 个 token 的文本，你把它渲染出来，通过控制 tokenizer 的参数和控制分辨率，让它只输出 100 个视觉 token，但就把这 100 个视觉 token 扔给这个 3B 的 LLM。它能够以 97% 的精度还原这 1000 个 token 的文本，这就是所谓的信息压缩率达到 10 倍。\n\n他们做的这段事情和这个结论有很大的创新意义。\n\n1. 目前主流多模态LLM都是纯文本的地位比图像持平或者更高。但DeepseekOCR提供了一些强有力的证据，来证明Vision作为一种modality，比text要更高效，信息密度更大。这跟以前大家的直觉完全不一样。与此同时很多视觉信息没办法用文本表示出来，但文本的信息可以直接渲染成图片。这就引导着多模态未来的发展方向可能会让视觉的地位要高于文本。这不是定论，但是个很大的变革。\n2. 它给LLM解码的过程也带来了很大的灵活性。LLM在解码的时候可以先用一个zoom out view来得到（literally）big picture。等它需要具体看某一个地方的时候它再把这块图像给放大截取出来做进一步分析。像这种流程，如果在文本模态上做这一步会非常artificial。但是在图像模态上做这一步非常自然：就是图像的放大和缩小。\n3. 这个和记忆也有关。人类的记忆是分层的，短期记忆往往是非常精确的，长期记忆就只记得一个大概。这个天然就对应着上面说的放缩解码过程。长期记忆就缩小一点，短期记忆就放大一点。所以DeepseekOCR提供了一种非常自然的多层次记忆/context windows compression的实现方法，甚至可以理论上可以做一种无限延伸的记忆。\n\n当然，这只是一个早期的工作，比如OCR做得好并不等于推理、幻觉等等方面也会很好。最终视觉模态会不会比文本更好需要更多的实验。我们讨论的多层次记忆很让人激动，但目前DeepseekOCR只实现了（非常精巧的）tokenizer内部的多分辨率编码。LLM交互式地主动去凑近了看，这个还是我们的构想，不是说已经有开源实现了。但总的来说，这个思路和初步的实验结果给了人很多想象空间。"
      },
      {
        "name": "信息",
        "keywords": [
          "信息"
        ],
        "count": 9,
        "representative": "分享一些针对Deepseek OCR的学习笔记。注意这些材料在直观性和严谨性上更强调直观性。如果希望有严谨性的话还是得去看原论文。\n\nDeepSeekOCR想解决的问题其实跟 OCR 没关系。它的直接出发点非常 DeepSeek。就是 LLM 是基于 Transformer 的，Transformer context window 一长，它不论是占用的显存还是需要的算力都是平方量级增长的，又慢又贵。Deepseek用了一个非常直观的方法去部分解决这个问题：token 压缩。比如 100 个 token 的文本，我用其他模态比如图片，可能 10 个 token 就能表达出来同样的含义，这样就可以省很多钱，也可以用更小的显卡。\n\n但是如果真的要做这件事情，一个正统的方法是，我们把普通 LLM 前面的 tokenizer 从文本 tokenizer 换成图像的 tokenizer，然后从头训练一个 LLM，然后在各种任务上面测试，比如让它写程序、做问答、调用工具，看看效果会不会变好。很显然这个非常重量级。那有没有一个任务，它又能验证这种信息压缩的思路对不对，又能不要这么重量级，又足够有说服力呢？OCR 就是一个这样的例子。\n\n具体地说，DeepSeek 先是把文本渲染成图像，这样就知道原始信息ground truth是什么。然后再把图像用他们的 tokenizer 进行处理，得到一堆token，这一步跟文本得到token概念上类似。然后再用一个非常小的 3B 的 LLM 进行解码。就是问它：你从这些 token 里面能不能反推出来它最初输入的那些文本是什么。这就形成了一个定量的 evaluation 的框架。基于这个框架，他们给出了一个非常惊人的结果，原来有 1000 个 token 的文本，你把它渲染出来，通过控制 tokenizer 的参数和控制分辨率，让它只输出 100 个视觉 token，但就把这 100 个视觉 token 扔给这个 3B 的 LLM。它能够以 97% 的精度还原这 1000 个 token 的文本，这就是所谓的信息压缩率达到 10 倍。\n\n他们做的这段事情和这个结论有很大的创新意义。\n\n1. 目前主流多模态LLM都是纯文本的地位比图像持平或者更高。但DeepseekOCR提供了一些强有力的证据，来证明Vision作为一种modality，比text要更高效，信息密度更大。这跟以前大家的直觉完全不一样。与此同时很多视觉信息没办法用文本表示出来，但文本的信息可以直接渲染成图片。这就引导着多模态未来的发展方向可能会让视觉的地位要高于文本。这不是定论，但是个很大的变革。\n2. 它给LLM解码的过程也带来了很大的灵活性。LLM在解码的时候可以先用一个zoom out view来得到（literally）big picture。等它需要具体看某一个地方的时候它再把这块图像给放大截取出来做进一步分析。像这种流程，如果在文本模态上做这一步会非常artificial。但是在图像模态上做这一步非常自然：就是图像的放大和缩小。\n3. 这个和记忆也有关。人类的记忆是分层的，短期记忆往往是非常精确的，长期记忆就只记得一个大概。这个天然就对应着上面说的放缩解码过程。长期记忆就缩小一点，短期记忆就放大一点。所以DeepseekOCR提供了一种非常自然的多层次记忆/context windows compression的实现方法，甚至可以理论上可以做一种无限延伸的记忆。\n\n当然，这只是一个早期的工作，比如OCR做得好并不等于推理、幻觉等等方面也会很好。最终视觉模态会不会比文本更好需要更多的实验。我们讨论的多层次记忆很让人激动，但目前DeepseekOCR只实现了（非常精巧的）tokenizer内部的多分辨率编码。LLM交互式地主动去凑近了看，这个还是我们的构想，不是说已经有开源实现了。但总的来说，这个思路和初步的实验结果给了人很多想象空间。"
      },
      {
        "name": "文本",
        "keywords": [
          "文本"
        ],
        "count": 3,
        "representative": "分享一些针对Deepseek OCR的学习笔记。注意这些材料在直观性和严谨性上更强调直观性。如果希望有严谨性的话还是得去看原论文。\n\nDeepSeekOCR想解决的问题其实跟 OCR 没关系。它的直接出发点非常 DeepSeek。就是 LLM 是基于 Transformer 的，Transformer context window 一长，它不论是占用的显存还是需要的算力都是平方量级增长的，又慢又贵。Deepseek用了一个非常直观的方法去部分解决这个问题：token 压缩。比如 100 个 token 的文本，我用其他模态比如图片，可能 10 个 token 就能表达出来同样的含义，这样就可以省很多钱，也可以用更小的显卡。\n\n但是如果真的要做这件事情，一个正统的方法是，我们把普通 LLM 前面的 tokenizer 从文本 tokenizer 换成图像的 tokenizer，然后从头训练一个 LLM，然后在各种任务上面测试，比如让它写程序、做问答、调用工具，看看效果会不会变好。很显然这个非常重量级。那有没有一个任务，它又能验证这种信息压缩的思路对不对，又能不要这么重量级，又足够有说服力呢？OCR 就是一个这样的例子。\n\n具体地说，DeepSeek 先是把文本渲染成图像，这样就知道原始信息ground truth是什么。然后再把图像用他们的 tokenizer 进行处理，得到一堆token，这一步跟文本得到token概念上类似。然后再用一个非常小的 3B 的 LLM 进行解码。就是问它：你从这些 token 里面能不能反推出来它最初输入的那些文本是什么。这就形成了一个定量的 evaluation 的框架。基于这个框架，他们给出了一个非常惊人的结果，原来有 1000 个 token 的文本，你把它渲染出来，通过控制 tokenizer 的参数和控制分辨率，让它只输出 100 个视觉 token，但就把这 100 个视觉 token 扔给这个 3B 的 LLM。它能够以 97% 的精度还原这 1000 个 token 的文本，这就是所谓的信息压缩率达到 10 倍。\n\n他们做的这段事情和这个结论有很大的创新意义。\n\n1. 目前主流多模态LLM都是纯文本的地位比图像持平或者更高。但DeepseekOCR提供了一些强有力的证据，来证明Vision作为一种modality，比text要更高效，信息密度更大。这跟以前大家的直觉完全不一样。与此同时很多视觉信息没办法用文本表示出来，但文本的信息可以直接渲染成图片。这就引导着多模态未来的发展方向可能会让视觉的地位要高于文本。这不是定论，但是个很大的变革。\n2. 它给LLM解码的过程也带来了很大的灵活性。LLM在解码的时候可以先用一个zoom out view来得到（literally）big picture。等它需要具体看某一个地方的时候它再把这块图像给放大截取出来做进一步分析。像这种流程，如果在文本模态上做这一步会非常artificial。但是在图像模态上做这一步非常自然：就是图像的放大和缩小。\n3. 这个和记忆也有关。人类的记忆是分层的，短期记忆往往是非常精确的，长期记忆就只记得一个大概。这个天然就对应着上面说的放缩解码过程。长期记忆就缩小一点，短期记忆就放大一点。所以DeepseekOCR提供了一种非常自然的多层次记忆/context windows compression的实现方法，甚至可以理论上可以做一种无限延伸的记忆。\n\n当然，这只是一个早期的工作，比如OCR做得好并不等于推理、幻觉等等方面也会很好。最终视觉模态会不会比文本更好需要更多的实验。我们讨论的多层次记忆很让人激动，但目前DeepseekOCR只实现了（非常精巧的）tokenizer内部的多分辨率编码。LLM交互式地主动去凑近了看，这个还是我们的构想，不是说已经有开源实现了。但总的来说，这个思路和初步的实验结果给了人很多想象空间。"
      },
      {
        "name": "非常",
        "keywords": [
          "非常"
        ],
        "count": 3,
        "representative": "分享一些针对Deepseek OCR的学习笔记。注意这些材料在直观性和严谨性上更强调直观性。如果希望有严谨性的话还是得去看原论文。\n\nDeepSeekOCR想解决的问题其实跟 OCR 没关系。它的直接出发点非常 DeepSeek。就是 LLM 是基于 Transformer 的，Transformer context window 一长，它不论是占用的显存还是需要的算力都是平方量级增长的，又慢又贵。Deepseek用了一个非常直观的方法去部分解决这个问题：token 压缩。比如 100 个 token 的文本，我用其他模态比如图片，可能 10 个 token 就能表达出来同样的含义，这样就可以省很多钱，也可以用更小的显卡。\n\n但是如果真的要做这件事情，一个正统的方法是，我们把普通 LLM 前面的 tokenizer 从文本 tokenizer 换成图像的 tokenizer，然后从头训练一个 LLM，然后在各种任务上面测试，比如让它写程序、做问答、调用工具，看看效果会不会变好。很显然这个非常重量级。那有没有一个任务，它又能验证这种信息压缩的思路对不对，又能不要这么重量级，又足够有说服力呢？OCR 就是一个这样的例子。\n\n具体地说，DeepSeek 先是把文本渲染成图像，这样就知道原始信息ground truth是什么。然后再把图像用他们的 tokenizer 进行处理，得到一堆token，这一步跟文本得到token概念上类似。然后再用一个非常小的 3B 的 LLM 进行解码。就是问它：你从这些 token 里面能不能反推出来它最初输入的那些文本是什么。这就形成了一个定量的 evaluation 的框架。基于这个框架，他们给出了一个非常惊人的结果，原来有 1000 个 token 的文本，你把它渲染出来，通过控制 tokenizer 的参数和控制分辨率，让它只输出 100 个视觉 token，但就把这 100 个视觉 token 扔给这个 3B 的 LLM。它能够以 97% 的精度还原这 1000 个 token 的文本，这就是所谓的信息压缩率达到 10 倍。\n\n他们做的这段事情和这个结论有很大的创新意义。\n\n1. 目前主流多模态LLM都是纯文本的地位比图像持平或者更高。但DeepseekOCR提供了一些强有力的证据，来证明Vision作为一种modality，比text要更高效，信息密度更大。这跟以前大家的直觉完全不一样。与此同时很多视觉信息没办法用文本表示出来，但文本的信息可以直接渲染成图片。这就引导着多模态未来的发展方向可能会让视觉的地位要高于文本。这不是定论，但是个很大的变革。\n2. 它给LLM解码的过程也带来了很大的灵活性。LLM在解码的时候可以先用一个zoom out view来得到（literally）big picture。等它需要具体看某一个地方的时候它再把这块图像给放大截取出来做进一步分析。像这种流程，如果在文本模态上做这一步会非常artificial。但是在图像模态上做这一步非常自然：就是图像的放大和缩小。\n3. 这个和记忆也有关。人类的记忆是分层的，短期记忆往往是非常精确的，长期记忆就只记得一个大概。这个天然就对应着上面说的放缩解码过程。长期记忆就缩小一点，短期记忆就放大一点。所以DeepseekOCR提供了一种非常自然的多层次记忆/context windows compression的实现方法，甚至可以理论上可以做一种无限延伸的记忆。\n\n当然，这只是一个早期的工作，比如OCR做得好并不等于推理、幻觉等等方面也会很好。最终视觉模态会不会比文本更好需要更多的实验。我们讨论的多层次记忆很让人激动，但目前DeepseekOCR只实现了（非常精巧的）tokenizer内部的多分辨率编码。LLM交互式地主动去凑近了看，这个还是我们的构想，不是说已经有开源实现了。但总的来说，这个思路和初步的实验结果给了人很多想象空间。"
      }
    ],
    "imageCount": 12,
    "groupVibes": {
      "score": 61,
      "activity": 1,
      "sentiment": 0.48,
      "infoDensity": 0.37,
      "controversy": 0.09,
      "tone": "讨论平稳",
      "reasons": [
        "活跃度高（92 条、20 人参与）",
        "讨论较温和，可适度引导观点碰撞"
      ]
    },
    "replyDebt": {
      "outstanding": [
        {
          "questioner": "hulu968988",
          "question": "请问下，智谱这块大家有熟悉的销售嘛",
          "askedAt": "2025-10-24T11:16:28+08:00",
          "ageMinutes": 145.9
        },
        {
          "questioner": "CuBiCWu",
          "question": "号称了啥，反正论文和开源模型都在。容易验证也容易证伪的。但是我觉得这个方向的确是在触及信息论的底层基础。庞大的信息量是如何被我们可怜的脑计算机处理的。特斯拉不走寻常路的智驾方案建立在什么理论上。都是这个方面的研究",
          "askedAt": "2025-10-24T12:11:05+08:00",
          "ageMinutes": 91.2
        },
        {
          "questioner": "parasuc",
          "question": "测试的效果怎么样呢？",
          "askedAt": "2025-10-24T12:16:37+08:00",
          "ageMinutes": 85.7
        },
        {
          "questioner": "oldbruce",
          "question": "# LLM 在空白输入时的幻觉问题\n\n## 背景\n\n在日常使用 LLM 的过程中，我和团队成员都注意到一个共性问题：当输入内容为空白或信息量极少时，LLM 的幻觉现象会格外明显。本文整理了几个实际场景中遇到的典型案例，以及对应的应对思路。\n…",
          "askedAt": "2025-10-24T12:27:00+08:00",
          "ageMinutes": 75.3
        },
        {
          "questioner": "wxid_dzsyarbsokqs22",
          "question": "编码和语义是不是两个概念呢？",
          "askedAt": "2025-10-24T13:42:19+08:00"
        }
      ],
      "resolved": [
        {
          "questioner": "grapeot",
          "question": "分享一些针对Deepseek OCR的学习笔记。注意这些材料在直观性和严谨性上更强调直观性。如果希望有严谨性的话还是得去看原论文。\n\nDeepSeekOCR想解决的问题其实跟 OCR 没关系。它的直接出发点非常 DeepSeek。就是 LL…",
          "askedAt": "2025-10-24T11:55:14+08:00",
          "responseMinutes": 8.8,
          "responders": [
            "CuBiCWu"
          ]
        }
      ],
      "avgResponseMinutes": 8.8,
      "bestResponseHours": [
        12
      ]
    }
  },
  "talker": "27587714869@chatroom"
}
